{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868a625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.signal import hilbert\n",
    "from pathlib import Path\n",
    "import mne\n",
    "\n",
    "# Channel renaming\n",
    "channel_mapping = {\n",
    "    \"EEG Fp1\": \"Fp1\", \"EEG Fp2\": \"Fp2\", \"EEG F3\": \"F3\", \"EEG F4\": \"F4\",\n",
    "    \"EEG F7\": \"F7\", \"EEG F8\": \"F8\", \"EEG T3\": \"T3\", \"EEG T4\": \"T4\",\n",
    "    \"EEG C3\": \"C3\", \"EEG C4\": \"C4\", \"EEG T5\": \"T5\", \"EEG T6\": \"T6\",\n",
    "    \"EEG P3\": \"P3\", \"EEG P4\": \"P4\", \"EEG O1\": \"O1\", \"EEG O2\": \"O2\",\n",
    "    \"EEG Fz\": \"Fz\", \"EEG Cz\": \"Cz\", \"EEG Pz\": \"Pz\"\n",
    "}\n",
    "channels = list(channel_mapping.values())\n",
    "\n",
    "# Frequency bands\n",
    "bands = {\n",
    "    'delta': (1, 4),\n",
    "    'theta': (4, 8),\n",
    "    'alpha': (8, 12),\n",
    "    'beta': (12, 30),\n",
    "    'gamma': (30, 45),\n",
    "    'broadband': (1, 45)\n",
    "}\n",
    "\n",
    "# Envelope extractor per subject\n",
    "def extract_band_envelopes(raw, bands=bands, channels=channels):\n",
    "    raw = raw.copy()\n",
    "\n",
    "    # Clean and restrict to EEG channels\n",
    "    raw.rename_channels(lambda ch: ch.replace(\"EEG \", \"\") if ch.startswith(\"EEG \") else ch)\n",
    "    raw.pick_channels(channels)\n",
    "    raw.set_eeg_reference('average', projection=False)\n",
    "\n",
    "    band_envelopes = {}\n",
    "    for band, (low, high) in bands.items():\n",
    "        try:\n",
    "            # Bandpass\n",
    "            raw_band = raw.copy().filter(low, high, fir_design='firwin', verbose=False)\n",
    "            data = raw_band.get_data()\n",
    "\n",
    "            # Hilbert envelope\n",
    "            analytic = hilbert(data, axis=1)\n",
    "            envelope = np.abs(analytic)\n",
    "\n",
    "            # Average over channels\n",
    "            mean_envelope = np.mean(envelope, axis=0)\n",
    "            band_envelopes[band] = mean_envelope\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed band {band}: {e}\")\n",
    "    return band_envelopes\n",
    "\n",
    "# Batch processor\n",
    "def process_all_subjects(eeg_dict, label=\"rest\"):\n",
    "    band_data = {}\n",
    "    for subj_id, raw in eeg_dict.items():\n",
    "        try:\n",
    "            band_data[subj_id] = extract_band_envelopes(raw)\n",
    "            print(f\"‚úÖ {label.upper()} subject {subj_id} processed.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {label.upper()} subject {subj_id} failed: {e}\")\n",
    "    return band_data\n",
    "\n",
    "# === Load EEG dicts ===\n",
    "with open(\"/home/donaf-strange/LAB_WORK/eeg_arithmetic_project/data/all_rest_eeg_by_participant.pkl\", \"rb\") as f:\n",
    "    rest_eeg_dict = pickle.load(f)\n",
    "\n",
    "with open(\"/home/donaf-strange/LAB_WORK/eeg_arithmetic_project/data/all_task_eeg_by_participant.pkl\", \"rb\") as f:\n",
    "    task_eeg_dict = pickle.load(f)\n",
    "\n",
    "# === Run ===\n",
    "band_env_rest = process_all_subjects(rest_eeg_dict, label=\"rest\")\n",
    "band_env_task = process_all_subjects(task_eeg_dict, label=\"task\")\n",
    "\n",
    "# === Save ===\n",
    "Path(\"band_envelopes\").mkdir(exist_ok=True)\n",
    "\n",
    "with open(\"band_envelopes/band_envelopes_rest.pkl\", \"wb\") as f:\n",
    "    pickle.dump(band_env_rest, f)\n",
    "\n",
    "with open(\"band_envelopes/band_envelopes_task.pkl\", \"wb\") as f:\n",
    "    pickle.dump(band_env_task, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90662e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jansen_rit_simulate(A=3.25, B=22, C=135, mu=120, dt=0.0001, duration=1.0):\n",
    "    \"\"\"Simulates Jansen-Rit model and returns output EEG signal\"\"\"\n",
    "    t = np.arange(0, duration, dt)\n",
    "    n = len(t)\n",
    "\n",
    "    # State variables\n",
    "    y0 = np.zeros(n)\n",
    "    y1 = np.zeros(n)\n",
    "    y2 = np.zeros(n)\n",
    "    y3 = np.zeros(n)\n",
    "    y4 = np.zeros(n)\n",
    "    y5 = np.zeros(n)\n",
    "\n",
    "    # Parameters\n",
    "    a = 100.0  # excitatory time constant\n",
    "    b = 50.0   # inhibitory time constant\n",
    "    e0 = 2.5\n",
    "    v0 = 6.0\n",
    "    r = 0.56\n",
    "\n",
    "    def sigmoid(v):\n",
    "        return 2 * e0 / (1 + np.exp(r * (v0 - v)))\n",
    "\n",
    "    for i in range(2, n):\n",
    "        p = mu + np.random.randn() * 2.0  # white noise input\n",
    "\n",
    "        y0[i] = y0[i-1] + dt * y3[i-1]\n",
    "        y3[i] = y3[i-1] + dt * (A * a * sigmoid(y1[i-1] - y2[i-1]) - 2 * a * y3[i-1] - a**2 * y0[i-1])\n",
    "        y1[i] = y1[i-1] + dt * y4[i-1]\n",
    "        y4[i] = y4[i-1] + dt * (A * a * (p + C * sigmoid(C * y0[i-1])) - 2 * a * y4[i-1] - a**2 * y1[i-1])\n",
    "        y2[i] = y2[i-1] + dt * y5[i-1]\n",
    "        y5[i] = y5[i-1] + dt * (B * b * C * sigmoid(C * y0[i-1]) - 2 * b * y5[i-1] - b**2 * y2[i-1])\n",
    "\n",
    "    return y1 - y2  # pyramidal output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65dd824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the pickle file\n",
    "with open(\"band_envelopes/band_envelopes_rest.pkl\", \"rb\") as f:\n",
    "    band_envelopes_rest = pickle.load(f)\n",
    "\n",
    "# Print top-level keys (subject IDs)\n",
    "print(\"Subject IDs:\", list(band_envelopes_rest.keys())[:5])  # show a few subjects\n",
    "\n",
    "# Pick one subject\n",
    "example_subject = list(band_envelopes_rest.keys())[0]\n",
    "\n",
    "# Print bands available for that subject\n",
    "print(f\"\\nAvailable bands for subject {example_subject}:\")\n",
    "print(band_envelopes_rest[example_subject].keys())\n",
    "\n",
    "# Print size of each band signal\n",
    "for band, signal in band_envelopes_rest[example_subject].items():\n",
    "    print(f\"  {band}: shape = {len(signal)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69148b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.optimize import differential_evolution\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# === Jansen-Rit model ===\n",
    "def jansen_rit_simulate(A=3.25, B=22, C=135, mu=120, dt=0.002, duration=1.0, noise_std=2.0):\n",
    "    t = np.arange(0, duration, dt)\n",
    "    n = len(t)\n",
    "\n",
    "    y0, y1, y2 = np.zeros(n), np.zeros(n), np.zeros(n)\n",
    "    y3, y4, y5 = np.zeros(n), np.zeros(n), np.zeros(n)\n",
    "\n",
    "    a, b = 100.0, 50.0\n",
    "    e0, v0, r = 2.5, 6.0, 0.56\n",
    "\n",
    "    def sigmoid(v): return 2 * e0 / (1 + np.exp(r * (v0 - v)))\n",
    "\n",
    "    for i in range(2, n):\n",
    "        p = mu + np.random.normal(0, noise_std)\n",
    "\n",
    "        y0[i] = y0[i-1] + dt * y3[i-1]\n",
    "        y3[i] = y3[i-1] + dt * (A * a * sigmoid(y1[i-1] - y2[i-1]) - 2 * a * y3[i-1] - a**2 * y0[i-1])\n",
    "\n",
    "        y1[i] = y1[i-1] + dt * y4[i-1]\n",
    "        y4[i] = y4[i-1] + dt * (A * a * (p + C * sigmoid(C * y0[i-1])) - 2 * a * y4[i-1] - a**2 * y1[i-1])\n",
    "\n",
    "        y2[i] = y2[i-1] + dt * y5[i-1]\n",
    "        y5[i] = y5[i-1] + dt * (B * b * C * sigmoid(C * y0[i-1]) - 2 * b * y5[i-1] - b**2 * y2[i-1])\n",
    "\n",
    "    return y1 - y2  # Output\n",
    "\n",
    "# === Cost function ===\n",
    "def cost_function(params, target_signal, dt, duration):\n",
    "    A, B, C, mu = params\n",
    "    sim = jansen_rit_simulate(A=A, B=B, C=C, mu=mu, dt=dt, duration=duration)\n",
    "\n",
    "    sim_len = len(sim)\n",
    "    target_resampled = np.interp(\n",
    "        np.linspace(0, len(target_signal) - 1, sim_len),\n",
    "        np.arange(len(target_signal)),\n",
    "        target_signal\n",
    "    )\n",
    "\n",
    "    sim_z = (sim - np.mean(sim)) / np.std(sim)\n",
    "    tgt_z = (target_resampled - np.mean(target_resampled)) / np.std(target_resampled)\n",
    "\n",
    "    return np.mean((sim_z - tgt_z) ** 2)\n",
    "\n",
    "# === Fitting loop for any dataset ===\n",
    "def fit_all_subjects(band_envelopes_dict, label=\"rest\"):\n",
    "    dt = 0.002\n",
    "    duration = 1.0\n",
    "    bounds = [(2, 6), (10, 30), (100, 150), (80, 140)]  # A, B, C, mu\n",
    "\n",
    "    fitted_params = {}\n",
    "    print(f\"\\nüöÄ Starting parameter fitting for {label.upper()} data...\")\n",
    "\n",
    "    for subj_id, bands in band_envelopes_dict.items():\n",
    "        if \"alpha\" not in bands:\n",
    "            print(f\"‚ö†Ô∏è Skipping subject {subj_id} (no alpha band)\")\n",
    "            continue\n",
    "        try:\n",
    "            target_signal = bands[\"alpha\"]\n",
    "            print(f\"üîç Fitting subject {subj_id}...\")\n",
    "\n",
    "            result = differential_evolution(\n",
    "                func=cost_function,\n",
    "                bounds=bounds,\n",
    "                args=(target_signal, dt, duration),\n",
    "                strategy='best1bin',\n",
    "                maxiter=50,\n",
    "                popsize=10,\n",
    "                tol=1e-5,\n",
    "                polish=True,\n",
    "                disp=False\n",
    "            )\n",
    "\n",
    "            fitted_params[subj_id] = {\n",
    "                \"A\": result.x[0],\n",
    "                \"B\": result.x[1],\n",
    "                \"C\": result.x[2],\n",
    "                \"mu\": result.x[3],\n",
    "                \"loss\": result.fun\n",
    "            }\n",
    "\n",
    "            print(f\"‚úÖ {label.capitalize()} | Subject {subj_id} | Loss = {result.fun:.5f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed for subject {subj_id}: {e}\")\n",
    "\n",
    "    # Save results\n",
    "    Path(\"jansen_rit\").mkdir(exist_ok=True)\n",
    "    save_path = f\"jansen_rit/fitted_params_{label}.pkl\"\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        pickle.dump(fitted_params, f)\n",
    "\n",
    "    print(f\"üíæ Saved fitted parameters to {save_path}\")\n",
    "    print(f\"üìä Total successful fits: {len(fitted_params)} / {len(band_envelopes_dict)}\\n\")\n",
    "    return fitted_params\n",
    "\n",
    "# === Load both datasets ===\n",
    "with open(\"band_envelopes/band_envelopes_rest.pkl\", \"rb\") as f:\n",
    "    band_env_rest = pickle.load(f)\n",
    "\n",
    "with open(\"band_envelopes/band_envelopes_task.pkl\", \"rb\") as f:\n",
    "    band_env_task = pickle.load(f)\n",
    "\n",
    "# === Run fitting\n",
    "fitted_rest = fit_all_subjects(band_env_rest, label=\"rest\")\n",
    "fitted_task = fit_all_subjects(band_env_task, label=\"task\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1b5807",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# === Function to load and save RIT features ===\n",
    "def save_rit_features_for_ml(condition_label):\n",
    "    param_file = f\"jansen_rit/fitted_params_{condition_label}.pkl\"\n",
    "    output_file = f\"all_features/rit_features_{condition_label}.pkl\"\n",
    "\n",
    "    try:\n",
    "        with open(param_file, \"rb\") as f:\n",
    "            param_dict = pickle.load(f)\n",
    "\n",
    "        # Just save the dict ‚Äî it's already subject-wise and model parameter-wise\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            pickle.dump(param_dict, f)\n",
    "\n",
    "        print(f\"‚úÖ Saved RIT features to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to save features for {condition_label}: {e}\")\n",
    "\n",
    "# === Save both\n",
    "save_rit_features_for_ml(\"rest\")\n",
    "save_rit_features_for_ml(\"task\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c24016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# === Group Labels ===\n",
    "good_ids = ['1', '2', '3', '5', '7', '8', \n",
    "            '11', '12', '13', '15', '16', '17', \n",
    "            '18', '20', '23', '24', '25', '26', \n",
    "            '27', '28', '29', '31', '32', '33', \n",
    "            '34', '35']\n",
    "\n",
    "bad_ids = ['0', '4', '6', '9', '10', \n",
    "           '14', '19', '21', '22', '30']\n",
    "\n",
    "# === Bayesian comparison function ===\n",
    "def run_bayesian_parameter_comparison(param_name, param_dict, good_ids, bad_ids, title_label=\"REST\"):\n",
    "    # Extract data\n",
    "    good_vals = [param_dict[sid][param_name] for sid in good_ids if sid in param_dict and param_name in param_dict[sid]]\n",
    "    bad_vals = [param_dict[sid][param_name] for sid in bad_ids if sid in param_dict and param_name in param_dict[sid]]\n",
    "\n",
    "    if len(good_vals) < 3 or len(bad_vals) < 3:\n",
    "        print(f\"‚ö†Ô∏è Not enough data for parameter {param_name} in {title_label}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"\\nüìä Comparing parameter '{param_name}' in {title_label}\")\n",
    "    print(f\"  Good mean: {np.mean(good_vals):.3f}, Bad mean: {np.mean(bad_vals):.3f}\")\n",
    "\n",
    "    with pm.Model():\n",
    "        mu_good = pm.Normal(\"mu_good\", mu=0, sigma=10)\n",
    "        mu_bad = pm.Normal(\"mu_bad\", mu=0, sigma=10)\n",
    "        sigma = pm.HalfNormal(\"sigma\", sigma=10)\n",
    "\n",
    "        obs_good = pm.Normal(\"obs_good\", mu=mu_good, sigma=sigma, observed=good_vals)\n",
    "        obs_bad = pm.Normal(\"obs_bad\", mu=mu_bad, sigma=sigma, observed=bad_vals)\n",
    "\n",
    "        diff = pm.Deterministic(\"diff\", mu_good - mu_bad)\n",
    "\n",
    "        trace = pm.sample(2000, tune=1000, chains=4, target_accept=0.95, progressbar=True)\n",
    "\n",
    "    # Plot\n",
    "    #az.plot_posterior(trace, var_names=[\"diff\"], ref_val=0)\n",
    "    #plt.title(f\"Bayesian Comparison: {param_name} ({title_label})\")\n",
    "    #plt.tight_layout()\n",
    "    #plt.show()\n",
    "\n",
    "    return az.summary(trace, var_names=[\"diff\"])\n",
    "\n",
    "# === Function to process a condition (rest/task)\n",
    "def process_condition(condition_label):\n",
    "    param_file = f\"jansen_rit/fitted_params_{condition_label}.pkl\"\n",
    "    if not os.path.exists(param_file):\n",
    "        print(f\"‚ùå Missing file: {param_file}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n=== üîç Analyzing {condition_label.upper()} parameters ===\")\n",
    "\n",
    "    with open(param_file, \"rb\") as f:\n",
    "        param_dict = pickle.load(f)\n",
    "\n",
    "    summaries = {}\n",
    "    for param in [\"A\", \"B\", \"C\", \"mu\"]:\n",
    "        summary = run_bayesian_parameter_comparison(param, param_dict, good_ids, bad_ids, title_label=condition_label.upper())\n",
    "        if summary is not None:\n",
    "            summaries[param] = summary\n",
    "\n",
    "    # Print all results\n",
    "    print(f\"\\nüìå SUMMARY: {condition_label.upper()}\")\n",
    "    for param, table in summaries.items():\n",
    "        print(f\"\\nüîπ {param}:\\n{table}\\n\")\n",
    "\n",
    "# === Run for both conditions ===\n",
    "process_condition(\"rest\")\n",
    "process_condition(\"task\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ce4c65",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a75f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import entropy\n",
    "from pathlib import Path\n",
    "import nolds\n",
    "import os\n",
    "\n",
    "# === Jansen‚ÄìRit Simulator with all parameters ===\n",
    "def jansen_rit_simulate(A=3.25, B=22, C=135, mu=120, a=100.0, b=50.0, e0=2.5, v0=6.0, r=0.56,\n",
    "                        dt=0.002, duration=1.0, noise_std=2.0, pulse=None):\n",
    "    t = np.arange(0, duration, dt)\n",
    "    n = len(t)\n",
    "\n",
    "    y0, y1, y2 = np.zeros(n), np.zeros(n), np.zeros(n)\n",
    "    y3, y4, y5 = np.zeros(n), np.zeros(n), np.zeros(n)\n",
    "\n",
    "    def sigmoid(v):\n",
    "        return 2 * e0 / (1 + np.exp(r * (v0 - v)))\n",
    "\n",
    "    for i in range(2, n):\n",
    "        input_mu = mu\n",
    "        if pulse and pulse[0] < i * dt < pulse[1]:\n",
    "            input_mu += pulse[2]\n",
    "        p = input_mu + np.random.normal(0, noise_std)\n",
    "\n",
    "        y0[i] = y0[i-1] + dt * y3[i-1]\n",
    "        y3[i] = y3[i-1] + dt * (A * a * sigmoid(y1[i-1] - y2[i-1]) - 2 * a * y3[i-1] - a**2 * y0[i-1])\n",
    "\n",
    "        y1[i] = y1[i-1] + dt * y4[i-1]\n",
    "        y4[i] = y4[i-1] + dt * (A * a * (p + C * sigmoid(C * y0[i-1])) - 2 * a * y4[i-1] - a**2 * y1[i-1])\n",
    "\n",
    "        y2[i] = y2[i-1] + dt * y5[i-1]\n",
    "        y5[i] = y5[i-1] + dt * (B * b * C * sigmoid(C * y0[i-1]) - 2 * b * y5[i-1] - b**2 * y2[i-1])\n",
    "\n",
    "    return y1 - y2  # Output from pyramidal neurons\n",
    "\n",
    "# === Feature extractors ===\n",
    "def dominant_frequency(signal, sfreq=500):\n",
    "    freqs, psd = welch(signal, fs=sfreq)\n",
    "    return freqs[np.argmax(psd)]\n",
    "\n",
    "def signal_entropy(signal, bins=50):\n",
    "    hist, _ = np.histogram(signal, bins=bins, density=True)\n",
    "    return entropy(hist + 1e-8)\n",
    "\n",
    "def lyapunov_exponent(signal):\n",
    "    return nolds.lyap_r(signal)\n",
    "\n",
    "def erp_features(signal, dt=0.002):\n",
    "    peak_amp = np.max(signal)\n",
    "    latency = np.argmax(signal) * dt\n",
    "    width = np.sum(signal > (0.5 * peak_amp)) * dt\n",
    "    return {\n",
    "        \"erp_amp\": peak_amp,\n",
    "        \"erp_latency\": latency,\n",
    "        \"erp_width\": width\n",
    "    }\n",
    "\n",
    "# === Combine all features per subject ===\n",
    "def extract_extended_features(params, duration=1.0):\n",
    "    sim_params = {k: params[k] for k in ['A', 'B', 'C', 'mu']}\n",
    "    a, b = 100.0, 50.0\n",
    "    e0, v0, r = 2.5, 6.0, 0.56\n",
    "\n",
    "    sim = jansen_rit_simulate(**sim_params, a=a, b=b, e0=e0, v0=v0, r=r, duration=duration)\n",
    "\n",
    "    return {\n",
    "        **sim_params,\n",
    "        \"a\": a, \"b\": b,\n",
    "        \"e0\": e0, \"v0\": v0, \"r\": r,\n",
    "        \"dominant_freq\": dominant_frequency(sim),\n",
    "        \"entropy\": signal_entropy(sim),\n",
    "        \"lyapunov\": lyapunov_exponent(sim),\n",
    "        **erp_features(sim)\n",
    "    }\n",
    "\n",
    "# === Process a .pkl file and save extended features ===\n",
    "def extend_param_file(in_path, out_path, duration=1.0):\n",
    "    with open(in_path, \"rb\") as f:\n",
    "        fitted_params = pickle.load(f)\n",
    "\n",
    "    extended = {}\n",
    "    for subj_id, params in fitted_params.items():\n",
    "        try:\n",
    "            feats = extract_extended_features(params, duration=duration)\n",
    "            extended[subj_id] = feats\n",
    "            print(f\"‚úÖ Extended subject {subj_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed subject {subj_id}: {e}\")\n",
    "\n",
    "    Path(os.path.dirname(out_path)).mkdir(exist_ok=True)\n",
    "    with open(out_path, \"wb\") as f:\n",
    "        pickle.dump(extended, f)\n",
    "    print(f\"\\nüíæ Saved extended features to: {out_path}\")\n",
    "\n",
    "# === Run for both REST and TASK ===\n",
    "extend_param_file(\"jansen_rit/fitted_params_rest.pkl\", \"jansen_rit/fitted_params_rest_extended.pkl\")\n",
    "extend_param_file(\"jansen_rit/fitted_params_task.pkl\", \"jansen_rit/fitted_params_task_extended.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a20c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import entropy\n",
    "from scipy.optimize import differential_evolution\n",
    "from pathlib import Path\n",
    "import nolds\n",
    "import os\n",
    "\n",
    "# === Jansen-Rit Simulator ===\n",
    "def jansen_rit_simulate(A=3.25, B=22, C=135, mu=120, a=100.0, b=50.0, e0=2.5, v0=6.0, r=0.56,\n",
    "                        dt=0.002, duration=1.0, noise_std=2.0):\n",
    "    t = np.arange(0, duration, dt)\n",
    "    n = len(t)\n",
    "\n",
    "    y0, y1, y2 = np.zeros(n), np.zeros(n), np.zeros(n)\n",
    "    y3, y4, y5 = np.zeros(n), np.zeros(n), np.zeros(n)\n",
    "\n",
    "    def sigmoid(v):\n",
    "        return 2 * e0 / (1 + np.exp(r * (v0 - v)))\n",
    "\n",
    "    for i in range(2, n):\n",
    "        p = mu + np.random.normal(0, noise_std)\n",
    "\n",
    "        y0[i] = y0[i-1] + dt * y3[i-1]\n",
    "        y3[i] = y3[i-1] + dt * (A * a * sigmoid(y1[i-1] - y2[i-1]) - 2 * a * y3[i-1] - a**2 * y0[i-1])\n",
    "\n",
    "        y1[i] = y1[i-1] + dt * y4[i-1]\n",
    "        y4[i] = y4[i-1] + dt * (A * a * (p + C * sigmoid(C * y0[i-1])) - 2 * a * y4[i-1] - a**2 * y1[i-1])\n",
    "\n",
    "        y2[i] = y2[i-1] + dt * y5[i-1]\n",
    "        y5[i] = y5[i-1] + dt * (B * b * C * sigmoid(C * y0[i-1]) - 2 * b * y5[i-1] - b**2 * y2[i-1])\n",
    "\n",
    "    return y1 - y2  # Output signal\n",
    "\n",
    "# === Feature Extractors ===\n",
    "def dominant_frequency(signal, sfreq=500):\n",
    "    freqs, psd = welch(signal, fs=sfreq)\n",
    "    return freqs[np.argmax(psd)]\n",
    "\n",
    "def signal_entropy(signal, bins=50):\n",
    "    hist, _ = np.histogram(signal, bins=bins, density=True)\n",
    "    return entropy(hist + 1e-8)\n",
    "\n",
    "def lyapunov_exponent(signal):\n",
    "    return nolds.lyap_r(signal)\n",
    "\n",
    "def erp_features(signal, dt=0.002):\n",
    "    peak_amp = np.max(signal)\n",
    "    latency = np.argmax(signal) * dt\n",
    "    width = np.sum(signal > (0.5 * peak_amp)) * dt\n",
    "    return {\n",
    "        \"erp_amp\": peak_amp,\n",
    "        \"erp_latency\": latency,\n",
    "        \"erp_width\": width\n",
    "    }\n",
    "\n",
    "def extract_extended_features(params, duration=1.0):\n",
    "    sim = jansen_rit_simulate(**params, duration=duration)\n",
    "    return {\n",
    "        **params,\n",
    "        \"dominant_freq\": dominant_frequency(sim),\n",
    "        \"entropy\": signal_entropy(sim),\n",
    "        \"lyapunov\": lyapunov_exponent(sim),\n",
    "        **erp_features(sim)\n",
    "    }\n",
    "\n",
    "# === Cost function for optimization ===\n",
    "def cost_function(params, target_signal, dt, duration):\n",
    "    A, B, C, mu = params\n",
    "    sim = jansen_rit_simulate(A=A, B=B, C=C, mu=mu, dt=dt, duration=duration)\n",
    "\n",
    "    sim_len = len(sim)\n",
    "    target_resampled = np.interp(\n",
    "        np.linspace(0, len(target_signal) - 1, sim_len),\n",
    "        np.arange(len(target_signal)),\n",
    "        target_signal\n",
    "    )\n",
    "\n",
    "    sim_z = (sim - np.mean(sim)) / np.std(sim)\n",
    "    tgt_z = (target_resampled - np.mean(target_resampled)) / np.std(target_resampled)\n",
    "\n",
    "    return np.mean((sim_z - tgt_z) ** 2)\n",
    "\n",
    "# === Full Pipeline per Dataset (Rest/Task) ===\n",
    "def full_jansen_pipeline(band_envelopes_dict, label=\"rest\", duration=1.0):\n",
    "    dt = 0.002\n",
    "    bounds = [(2, 6), (10, 30), (100, 150), (80, 140)]  # A, B, C, mu\n",
    "\n",
    "    fitted_params = {}\n",
    "    extended_features = {}\n",
    "\n",
    "    print(f\"\\nüöÄ Starting full Jansen‚ÄìRit pipeline for {label.upper()}...\")\n",
    "\n",
    "    for subj_id, bands in band_envelopes_dict.items():\n",
    "        if \"alpha\" not in bands:\n",
    "            print(f\"‚ö†Ô∏è Skipping subject {subj_id} (no alpha band)\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            target_signal = bands[\"alpha\"]\n",
    "            print(f\"üîç Fitting subject {subj_id}...\")\n",
    "\n",
    "            result = differential_evolution(\n",
    "                func=cost_function,\n",
    "                bounds=bounds,\n",
    "                args=(target_signal, dt, duration),\n",
    "                strategy='best1bin',\n",
    "                maxiter=50,\n",
    "                popsize=10,\n",
    "                tol=1e-5,\n",
    "                polish=True,\n",
    "                disp=False\n",
    "            )\n",
    "\n",
    "            params = {\n",
    "                \"A\": result.x[0],\n",
    "                \"B\": result.x[1],\n",
    "                \"C\": result.x[2],\n",
    "                \"mu\": result.x[3],\n",
    "                \"a\": 100.0,\n",
    "                \"b\": 50.0,\n",
    "                \"e0\": 2.5,\n",
    "                \"v0\": 6.0,\n",
    "                \"r\": 0.56\n",
    "            }\n",
    "\n",
    "            fitted_params[subj_id] = params\n",
    "            extended_features[subj_id] = extract_extended_features(params, duration=duration)\n",
    "\n",
    "            print(f\"‚úÖ {label.capitalize()} | Subject {subj_id} | Loss = {result.fun:.5f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed for subject {subj_id}: {e}\")\n",
    "\n",
    "    # Save combined results\n",
    "    Path(\"jansen_rit\").mkdir(exist_ok=True)\n",
    "\n",
    "    combined_data = {\n",
    "        \"fitted_params\": fitted_params,\n",
    "        \"extended_features\": extended_features\n",
    "    }\n",
    "\n",
    "    with open(f\"jansen_rit/fitted_params_{label}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(combined_data, f)\n",
    "\n",
    "    print(f\"\\nüíæ Saved all results to jansen_rit/fitted_params_{label}.pkl\")\n",
    "    print(f\"üìä Total subjects processed: {len(fitted_params)} / {len(band_envelopes_dict)}\")\n",
    "\n",
    "\n",
    "    return fitted_params, extended_features\n",
    "\n",
    "# === Load EEG Band Envelope Data ===\n",
    "with open(\"band_envelopes/band_envelopes_rest.pkl\", \"rb\") as f:\n",
    "    band_env_rest = pickle.load(f)\n",
    "\n",
    "with open(\"band_envelopes/band_envelopes_task.pkl\", \"rb\") as f:\n",
    "    band_env_task = pickle.load(f)\n",
    "\n",
    "# === Run Combined Pipeline\n",
    "fitted_rest, extended_rest = full_jansen_pipeline(band_env_rest, label=\"rest\")\n",
    "fitted_task, extended_task = full_jansen_pipeline(band_env_task, label=\"task\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c745290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#improved\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import entropy\n",
    "from scipy.optimize import differential_evolution\n",
    "from scipy.integrate import solve_ivp\n",
    "from pathlib import Path\n",
    "import nolds\n",
    "import os\n",
    "\n",
    "# === Ornstein-Uhlenbeck noise generator ===\n",
    "def ou_process(n, dt, tau=0.05, sigma=1.0):\n",
    "    x = np.zeros(n)\n",
    "    for i in range(1, n):\n",
    "        x[i] = x[i-1] * np.exp(-dt / tau) + sigma * np.sqrt(1 - np.exp(-2 * dt / tau)) * np.random.randn()\n",
    "    return x\n",
    "\n",
    "# === Jansen‚ÄìRit ODE ===\n",
    "def jansen_rit_ode(t, state, A, B, C, mu, a, b, e0, v0, r, noise_t, t_array):\n",
    "    y0, y3, y1, y4, y2, y5 = state\n",
    "    idx = min(int(t / (t_array[1] - t_array[0])), len(noise_t) - 1)\n",
    "    p = mu + noise_t[idx]\n",
    "    S = lambda v: 2 * e0 / (1 + np.exp(r * (v0 - v)))\n",
    "\n",
    "    dy0 = y3\n",
    "    dy3 = A * a * S(y1 - y2) - 2 * a * y3 - a ** 2 * y0\n",
    "    dy1 = y4\n",
    "    dy4 = A * a * (p + C * S(C * y0)) - 2 * a * y4 - a ** 2 * y1\n",
    "    dy2 = y5\n",
    "    dy5 = B * b * C * S(C * y0) - 2 * b * y5 - b ** 2 * y2\n",
    "    return [dy0, dy3, dy1, dy4, dy2, dy5]\n",
    "\n",
    "# === Simulator ===\n",
    "def jansen_rit_simulate(A=3.25, B=22, C=135, mu=120, a=100.0, b=50.0,\n",
    "                        e0=2.5, v0=6.0, r=0.56, dt=0.002, duration=1.0, noise_std=2.0):\n",
    "    t = np.arange(0, duration, dt)\n",
    "    y0 = [0.0] * 6\n",
    "    noise_t = ou_process(len(t), dt, sigma=noise_std)\n",
    "\n",
    "    def ode_wrapper(ti, state):\n",
    "        return jansen_rit_ode(ti, state, A, B, C, mu, a, b, e0, v0, r, noise_t, t)\n",
    "\n",
    "    sol = solve_ivp(\n",
    "        fun=ode_wrapper,\n",
    "        t_span=(0, duration),\n",
    "        y0=y0,\n",
    "        t_eval=t,\n",
    "        method='RK45'\n",
    "    )\n",
    "    signal = sol.y[2] - sol.y[4]\n",
    "    return signal / (np.max(np.abs(signal)) + 1e-8)\n",
    "\n",
    "# === Feature Extractors ===\n",
    "def dominant_frequency(signal, sfreq=500):\n",
    "    freqs, psd = welch(signal, fs=sfreq)\n",
    "    return freqs[np.argmax(psd)]\n",
    "\n",
    "def signal_entropy(signal, bins=50):\n",
    "    hist, _ = np.histogram(signal, bins=bins, density=True)\n",
    "    return entropy(hist + 1e-8)\n",
    "\n",
    "def lyapunov_exponent(signal):\n",
    "    return nolds.lyap_r(signal)\n",
    "\n",
    "def erp_features(signal, dt=0.002):\n",
    "    peak_amp = np.max(signal)\n",
    "    latency = np.argmax(signal) * dt\n",
    "    width = np.sum(signal > (0.5 * peak_amp)) * dt\n",
    "    return {\"erp_amp\": peak_amp, \"erp_latency\": latency, \"erp_width\": width}\n",
    "\n",
    "def extract_extended_features(params, duration=1.0):\n",
    "    sim = jansen_rit_simulate(**params, duration=duration)\n",
    "    return {\n",
    "        **params,\n",
    "        \"dominant_freq\": dominant_frequency(sim),\n",
    "        \"entropy\": signal_entropy(sim),\n",
    "        \"lyapunov\": lyapunov_exponent(sim),\n",
    "        **erp_features(sim)\n",
    "    }\n",
    "\n",
    "# === Cost function ===\n",
    "def cost_function(params_vec, target_signal, dt, duration):\n",
    "    A, B, C, mu = params_vec\n",
    "    params = {\n",
    "        \"A\": A, \"B\": B, \"C\": C, \"mu\": mu,\n",
    "        \"a\": 100.0, \"b\": 50.0,\n",
    "        \"e0\": 2.5, \"v0\": 6.0, \"r\": 0.56,\n",
    "        \"dt\": dt, \"noise_std\": 2.0\n",
    "    }\n",
    "    sim = jansen_rit_simulate(**params, duration=duration)\n",
    "    sim_len = len(sim)\n",
    "    target_resampled = np.interp(np.linspace(0, len(target_signal)-1, sim_len),\n",
    "                                 np.arange(len(target_signal)), target_signal)\n",
    "    sim_z = (sim - np.mean(sim)) / np.std(sim)\n",
    "    tgt_z = (target_resampled - np.mean(target_resampled)) / np.std(target_resampled)\n",
    "    return np.mean((sim_z - tgt_z) ** 2)\n",
    "\n",
    "# === Full Pipeline ===\n",
    "def full_jansen_pipeline(band_envelopes_dict, label=\"rest\", duration=1.0):\n",
    "    dt = 0.002\n",
    "    bounds = [(2, 6), (10, 30), (100, 150), (80, 140)]  # A, B, C, mu\n",
    "    fitted_params, extended_features = {}, {}\n",
    "\n",
    "    print(f\"\\nüöÄ Starting Jansen‚ÄìRit pipeline for {label.upper()}\")\n",
    "\n",
    "    for subj_id, bands in band_envelopes_dict.items():\n",
    "        if \"alpha\" not in bands:\n",
    "            print(f\"‚ö†Ô∏è Skipping subject {subj_id} (no alpha band)\")\n",
    "            continue\n",
    "        try:\n",
    "            target_signal = bands[\"alpha\"]\n",
    "            print(f\"üîç Fitting subject {subj_id}...\")\n",
    "\n",
    "            result = differential_evolution(\n",
    "                func=cost_function,\n",
    "                bounds=bounds,\n",
    "                args=(target_signal, dt, duration),\n",
    "                strategy='best1bin',\n",
    "                maxiter=50,\n",
    "                popsize=10,\n",
    "                tol=1e-5,\n",
    "                polish=True,\n",
    "                disp=False\n",
    "            )\n",
    "\n",
    "            params = {\n",
    "                \"A\": result.x[0], \"B\": result.x[1], \"C\": result.x[2], \"mu\": result.x[3],\n",
    "                \"a\": 100.0, \"b\": 50.0,\n",
    "                \"e0\": 2.5, \"v0\": 6.0, \"r\": 0.56,\n",
    "                \"dt\": dt, \"noise_std\": 2.0\n",
    "            }\n",
    "\n",
    "            fitted_params[subj_id] = params\n",
    "            extended_features[subj_id] = extract_extended_features(params, duration=duration)\n",
    "\n",
    "            print(f\"‚úÖ {label.capitalize()} | Subject {subj_id} | Loss = {result.fun:.5f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed for subject {subj_id}: {e}\")\n",
    "\n",
    "    # Save combined results\n",
    "    Path(\"jansen_rit\").mkdir(exist_ok=True)\n",
    "\n",
    "    combined_data = {\n",
    "        \"fitted_params\": fitted_params,\n",
    "        \"extended_features\": extended_features\n",
    "    }\n",
    "\n",
    "    with open(f\"jansen_rit/fitted_params_{label}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(combined_data, f)\n",
    "\n",
    "    print(f\"\\nüíæ Saved all results to jansen_rit/fitted_params_{label}.pkl\")\n",
    "    print(f\"üìä Total subjects processed: {len(fitted_params)} / {len(band_envelopes_dict)}\")\n",
    "    return fitted_params, extended_features\n",
    "\n",
    "# === Load Data and Run ===\n",
    "with open(\"band_envelopes/band_envelopes_rest.pkl\", \"rb\") as f:\n",
    "    band_env_rest = pickle.load(f)\n",
    "with open(\"band_envelopes/band_envelopes_task.pkl\", \"rb\") as f:\n",
    "    band_env_task = pickle.load(f)\n",
    "\n",
    "fitted_rest, extended_rest = full_jansen_pipeline(band_env_rest, label=\"rest\")\n",
    "fitted_task, extended_task = full_jansen_pipeline(band_env_task, label=\"task\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31246256",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Subjects in fitted_params:\", list(data['fitted_params'].keys()))\n",
    "print(\"Subjects in extended_features:\", list(data['extended_features'].keys()))\n",
    "# ids are stored in string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9c013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the saved file\n",
    "with open(\"jansen_rit/fitted_params_rest.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Access subject '1' (string key)\n",
    "subject_id = '1'\n",
    "\n",
    "# View fitted parameters\n",
    "print(f\"üìå Fitted Parameters for subject {subject_id}:\")\n",
    "print(data['fitted_params'][subject_id])\n",
    "\n",
    "# View extended features\n",
    "print(f\"\\nüìä Extended Features for subject {subject_id}:\")\n",
    "for k, v in data['extended_features'][subject_id].items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0939dc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# === Define subject groups ===\n",
    "good_ids = ['1', '2', '3', '5', '7', '8',\n",
    "            '11', '12', '13', '15', '16', '17',\n",
    "            '18', '20', '23', '24', '25', '26',\n",
    "            '27', '28', '29', '31', '32', '33',\n",
    "            '34', '35']\n",
    "\n",
    "bad_ids = ['0', '4', '6', '9', '10',\n",
    "           '14', '19', '21', '22', '30']\n",
    "\n",
    "# === Bayesian group comparison ===\n",
    "def bayesian_compare_feature(param_name, data_dict, good_ids, bad_ids, label=\"REST\"):\n",
    "    good_vals = [data_dict[sid][param_name] for sid in good_ids if sid in data_dict and param_name in data_dict[sid]]\n",
    "    bad_vals = [data_dict[sid][param_name] for sid in bad_ids if sid in data_dict and param_name in data_dict[sid]]\n",
    "\n",
    "    if len(good_vals) < 3 or len(bad_vals) < 3:\n",
    "        print(f\"‚ö†Ô∏è Not enough data for {param_name} in {label}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"\\nüìä {label}: Comparing '{param_name}'\")\n",
    "    print(f\"  Good mean: {np.mean(good_vals):.3f}, Bad mean: {np.mean(bad_vals):.3f}\")\n",
    "\n",
    "    with pm.Model():\n",
    "        mu_good = pm.Normal(\"mu_good\", mu=0, sigma=10)\n",
    "        mu_bad = pm.Normal(\"mu_bad\", mu=0, sigma=10)\n",
    "        sigma = pm.HalfNormal(\"sigma\", sigma=10)\n",
    "\n",
    "        pm.Normal(\"obs_good\", mu=mu_good, sigma=sigma, observed=good_vals)\n",
    "        pm.Normal(\"obs_bad\", mu=mu_bad, sigma=sigma, observed=bad_vals)\n",
    "\n",
    "        diff = pm.Deterministic(\"diff\", mu_good - mu_bad)\n",
    "\n",
    "        trace = pm.sample(2000, tune=1000, chains=4, target_accept=0.95, progressbar=True)\n",
    "\n",
    "    return az.summary(trace, var_names=[\"diff\"], hdi_prob=0.95)\n",
    "\n",
    "# === Function to process one .pkl file ===\n",
    "def process_feature_file(pkl_path, label=\"REST\"):\n",
    "    if not os.path.exists(pkl_path):\n",
    "        print(f\"‚ùå Missing file: {pkl_path}\")\n",
    "        return\n",
    "\n",
    "    with open(pkl_path, \"rb\") as f:\n",
    "        raw = pickle.load(f)\n",
    "\n",
    "    # Extract correct layer\n",
    "    if isinstance(raw, dict) and 'extended_features' in raw:\n",
    "        feature_dict = raw['extended_features']\n",
    "    else:\n",
    "        feature_dict = raw  # fallback (in case only flat dict is saved)\n",
    "\n",
    "    # Ensure all keys are strings\n",
    "    feature_dict = {str(k): v for k, v in feature_dict.items()}\n",
    "\n",
    "    # Detect scalar keys to compare\n",
    "    feature_keys = [k for k, v in next(iter(feature_dict.values())).items()\n",
    "                    if isinstance(v, (int, float, np.number)) and not isinstance(v, bool)]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    print(f\"\\n=== üîç Running Bayesian comparisons for {label.upper()} ===\")\n",
    "    for param in feature_keys:\n",
    "        summary = bayesian_compare_feature(param, feature_dict, good_ids, bad_ids, label=label)\n",
    "        if summary is not None:\n",
    "            results[param] = summary\n",
    "\n",
    "    # === Summary Table ===\n",
    "    print(f\"\\nüìå SUMMARY TABLE for {label.upper()}:\")\n",
    "    print(f\"{'Parameter':<20} {'Diff Mean':>10}   {'HDI (low - high)':>25}\")\n",
    "    print(\"-\" * 60)\n",
    "    for param, df in results.items():\n",
    "        mean = df.loc['diff', 'mean']\n",
    "\n",
    "        hdi_cols = [col for col in df.columns if 'hdi' in col]\n",
    "        if len(hdi_cols) >= 2:\n",
    "            hdi_low = df.loc['diff', hdi_cols[0]]\n",
    "            hdi_high = df.loc['diff', hdi_cols[1]]\n",
    "            print(f\"{param:<20} {mean:>10.3f}   [{hdi_low:.3f}, {hdi_high:.3f}]\")\n",
    "        else:\n",
    "            print(f\"{param:<20} {mean:>10.3f}   [HDI N/A]\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# === Run for REST and TASK ===\n",
    "results_rest = process_feature_file(\"jansen_rit/fitted_params_rest.pkl\", label=\"REST\")\n",
    "results_task = process_feature_file(\"jansen_rit/fitted_params_task.pkl\", label=\"TASK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edd35b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# === Input means and HDIs for C and mu ===\n",
    "# Format: {Condition: {Parameter: {Group: val, ...}}}\n",
    "summary = {\n",
    "    'Rest': {\n",
    "        'C': {'Good': 135 + 24.901/2, 'Bad': 135 - 24.901/2, 'HDI_low': 3.402, 'HDI_high': 47.227},\n",
    "        'mu': {'Good': 120 + 23.861/2, 'Bad': 120 - 23.861/2, 'HDI_low': 0.859, 'HDI_high': 47.100}\n",
    "    },\n",
    "    'Task': {\n",
    "        'C': {'Good': 135 + 21.335/2, 'Bad': 135 - 21.335/2, 'HDI_low': 0.171, 'HDI_high': 44.246},\n",
    "        'mu': {'Good': 120 + 27.078/2, 'Bad': 120 - 27.078/2, 'HDI_low': 4.246, 'HDI_high': 49.699}\n",
    "    }\n",
    "}\n",
    "\n",
    "# === Convert to long format DataFrame ===\n",
    "rows = []\n",
    "for cond in summary:\n",
    "    for param in summary[cond]:\n",
    "        g = summary[cond][param]['Good']\n",
    "        b = summary[cond][param]['Bad']\n",
    "        hdi_range = summary[cond][param]['HDI_high'] - summary[cond][param]['HDI_low']\n",
    "        rows.append([cond, param, 'Good', g, hdi_range])\n",
    "        rows.append([cond, param, 'Bad', b, hdi_range])\n",
    "df = pd.DataFrame(rows, columns=['Condition', 'Parameter', 'Group', 'Value', 'HDI'])\n",
    "\n",
    "# === Plot ===\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "\n",
    "for i, param in enumerate(['C', 'mu']):\n",
    "    ax = axes[i]\n",
    "    plot_df = df[df['Parameter'] == param]\n",
    "    sns.barplot(data=plot_df, x='Condition', y='Value', hue='Group', ax=ax,\n",
    "                palette=['#66c2a5', '#fc8d62'], ci=None)\n",
    "    \n",
    "    # Add error bars (HDI ranges)\n",
    "    for idx, row in plot_df.iterrows():\n",
    "        ax.errorbar(x=['Rest', 'Task'].index(row['Condition']) + (-0.2 if row['Group'] == 'Good' else 0.2),\n",
    "                    y=row['Value'], yerr=row['HDI'] / 2,\n",
    "                    fmt='none', ecolor='black', capsize=5)\n",
    "\n",
    "    ax.set_title(f\"Parameter: {param}\", fontsize=14)\n",
    "    ax.set_ylabel(\"Value\")\n",
    "    ax.set_xlabel(\"Condition\")\n",
    "    ax.set_ylim(bottom=100 if param == 'C' else 100)  # Adjust as needed\n",
    "\n",
    "axes[0].legend(title='Group')\n",
    "#plt.suptitle(\"üî¨ Group Differences in Jansen‚ÄìRit Parameters\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3a571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "# === Load fitted parameters ===\n",
    "with open(\"jansen_rit/fitted_params_rest_extended.pkl\", \"rb\") as f:\n",
    "    rest_params = pickle.load(f)\n",
    "\n",
    "with open(\"jansen_rit/fitted_params_task_extended.pkl\", \"rb\") as f:\n",
    "    task_params = pickle.load(f)\n",
    "\n",
    "# === Group definitions ===\n",
    "good_ids = ['1', '2', '3', '5', '7', '8', '11', '12', '13', '15', '16', '17',\n",
    "            '18', '20', '23', '24', '25', '26', '27', '28', '29', '31', '32', '33', '34', '35']\n",
    "\n",
    "bad_ids = ['0', '4', '6', '9', '10', '14', '19', '21', '22', '30']\n",
    "\n",
    "# === Function to extract group-wise values ===\n",
    "def extract_group_data(param_dict, param_name):\n",
    "    good_vals = [param_dict[sid][param_name] for sid in good_ids if sid in param_dict and param_name in param_dict[sid]]\n",
    "    bad_vals = [param_dict[sid][param_name] for sid in param_dict if sid in bad_ids and param_name in param_dict[sid]]\n",
    "    return good_vals, bad_vals\n",
    "\n",
    "# === Plot function ===\n",
    "def plot_violin_and_hdi(param_dict, param_list, condition=\"REST\"):\n",
    "    for param in param_list:\n",
    "        good_vals, bad_vals = extract_group_data(param_dict, param)\n",
    "        if len(good_vals) < 3 or len(bad_vals) < 3:\n",
    "            print(f\"Skipping {param} (insufficient data)\")\n",
    "            continue\n",
    "\n",
    "        # Plot violin\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.violinplot(data=[good_vals, bad_vals], palette=\"pastel\", inner=\"box\")\n",
    "        plt.xticks([0, 1], ['Good', 'Bad'])\n",
    "        plt.title(f\"{condition} ‚Äì {param}\")\n",
    "        plt.ylabel(param)\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Plot posterior difference (HDI)\n",
    "        with pm.Model():\n",
    "            mu_good = pm.Normal(\"mu_good\", mu=0, sigma=10)\n",
    "            mu_bad = pm.Normal(\"mu_bad\", mu=0, sigma=10)\n",
    "            sigma = pm.HalfNormal(\"sigma\", sigma=10)\n",
    "\n",
    "            pm.Normal(\"obs_good\", mu=mu_good, sigma=sigma, observed=good_vals)\n",
    "            pm.Normal(\"obs_bad\", mu=mu_bad, sigma=sigma, observed=bad_vals)\n",
    "\n",
    "            diff = pm.Deterministic(\"diff\", mu_good - mu_bad)\n",
    "            trace = pm.sample(2000, tune=1000, chains=4, target_accept=0.95, progressbar=False)\n",
    "\n",
    "        az.plot_posterior(trace, var_names=[\"diff\"], ref_val=0)\n",
    "        plt.title(f\"{condition} ‚Äì {param} (HDI of Group Diff)\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# === Parameters to plot ===\n",
    "core_params = [\"A\", \"B\", \"C\", \"mu\"]\n",
    "dyn_features = [\"dominant_freq\", \"entropy\", \"lyapunov\", \"erp_amp\", \"erp_latency\", \"erp_width\"]\n",
    "\n",
    "# === Run plots ===\n",
    "plot_violin_and_hdi(rest_params, core_params + dyn_features, condition=\"REST\")\n",
    "plot_violin_and_hdi(task_params, core_params + dyn_features, condition=\"TASK\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
